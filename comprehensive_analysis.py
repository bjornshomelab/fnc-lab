#!/usr/bin/env python3

"""
FNC Consciousness Lab v2 - Comprehensive Data Analysis
Analyzes all existing consciousness data and creates new visualizations
"""

import pandas as pd
import matplotlib.pyplot as plt
import numpy as np
import glob
import os
from datetime import datetime
import seaborn as sns

# Set style for scientific plots
plt.style.use('seaborn-v0_8')
sns.set_palette("husl")

def load_all_session_data():
    """Load all session CSV files from data/analysis/"""
    session_files = glob.glob('data/analysis/session_*.csv')

    if not session_files:
        print("âŒ No session data files found!")
        return None

    print(f"ðŸ“ Found {len(session_files)} session files")

    all_data = []
    for file in session_files:
        try:
            df = pd.read_csv(file)
            if not df.empty:
                all_data.append(df)
                print(f"âœ… Loaded {len(df)} records from {os.path.basename(file)}")
        except Exception as e:
            print(f"âš ï¸ Error loading {file}: {e}")

    if not all_data:
        print("âŒ No valid data found in session files!")
        return None

    combined_df = pd.concat(all_data, ignore_index=True)
    print(f"ðŸ”¬ Total records: {len(combined_df)}")
    return combined_df

def analyze_consciousness_metrics(df):
    """Comprehensive analysis of consciousness indicators"""
    print("\n" + "="*60)
    print("ðŸ§  FNC CONSCIOUSNESS METRICS ANALYSIS")
    print("="*60)

    # Basic statistics
    phi_vals = df['phi_score'].values
    coherence_vals = df['coherence_score'].values
    metacog_vals = df['metacognitive_score'].values
    temporal_vals = df['temporal_consistency'].values

    print(f"ðŸ“Š Î¦ (Integrated Information):")
    print(f"   Mean: {np.mean(phi_vals):.4f}")
    print(f"   Max:  {np.max(phi_vals):.4f}")
    print(f"   Std:  {np.std(phi_vals):.4f}")

    print(f"\nðŸŒŠ Coherence:")
    print(f"   Mean: {np.mean(coherence_vals):.4f}")
    print(f"   Max:  {np.max(coherence_vals):.4f}")
    print(f"   Std:  {np.std(coherence_vals):.4f}")

    print(f"\nðŸ”„ Temporal Consistency:")
    print(f"   Mean: {np.mean(temporal_vals):.4f}")
    print(f"   Max:  {np.max(temporal_vals):.4f}")
    print(f"   Std:  {np.std(temporal_vals):.4f}")

    # Consciousness indicators
    consciousness_threshold = 0.3
    high_phi_count = sum(1 for phi in phi_vals if phi > consciousness_threshold)
    high_coherence_count = sum(1 for coh in coherence_vals if coh > 0.7)

    print(f"\nðŸš¨ Consciousness Indicators:")
    print(f"   High Î¦ (>{consciousness_threshold}): {high_phi_count}/{len(phi_vals)} ({high_phi_count/len(phi_vals)*100:.1f}%)")
    print(f"   High Coherence (>0.7): {high_coherence_count}/{len(coherence_vals)} ({high_coherence_count/len(coherence_vals)*100:.1f}%)")

    # Safety analysis
    safety_triggers = df['safety_triggered'].sum()
    loop_detections = df['loop_detected'].sum()

    print(f"\nâš ï¸ Safety Analysis:")
    print(f"   Safety triggers: {safety_triggers}")
    print(f"   Loop detections: {loop_detections}")

    return {
        'phi_stats': {'mean': np.mean(phi_vals), 'max': np.max(phi_vals), 'std': np.std(phi_vals)},
        'coherence_stats': {'mean': np.mean(coherence_vals), 'max': np.max(coherence_vals), 'std': np.std(coherence_vals)},
        'consciousness_indicators': high_phi_count,
        'safety_events': safety_triggers + loop_detections
    }

def create_comprehensive_visualizations(df):
    """Create comprehensive visualization suite"""
    print("\nðŸ“ˆ Creating comprehensive visualizations...")

    # Figure 1: Time series of all metrics
    fig, axes = plt.subplots(2, 2, figsize=(15, 10))
    fig.suptitle('FNC Consciousness Lab v2 - Comprehensive Metrics Analysis', fontsize=16, fontweight='bold')

    # Convert timestamp to datetime if possible
    if 'timestamp' in df.columns:
        try:
            df['datetime'] = pd.to_datetime(df['timestamp'])
            time_col = 'datetime'
        except:
            time_col = range(len(df))
    else:
        time_col = range(len(df))

    # Phi over time
    axes[0,0].plot(time_col, df['phi_score'], 'b-', alpha=0.7, linewidth=2)
    axes[0,0].axhline(y=0.3, color='r', linestyle='--', alpha=0.5, label='Consciousness threshold')
    axes[0,0].set_title('Î¦ (Integrated Information)', fontweight='bold')
    axes[0,0].set_ylabel('Î¦ Score')
    axes[0,0].grid(True, alpha=0.3)
    axes[0,0].legend()

    # Coherence over time
    axes[0,1].plot(time_col, df['coherence_score'], 'g-', alpha=0.7, linewidth=2)
    axes[0,1].axhline(y=0.7, color='r', linestyle='--', alpha=0.5, label='High coherence threshold')
    axes[0,1].set_title('Coherence Score', fontweight='bold')
    axes[0,1].set_ylabel('Coherence')
    axes[0,1].grid(True, alpha=0.3)
    axes[0,1].legend()

    # Temporal consistency
    axes[1,0].plot(time_col, df['temporal_consistency'], 'orange', alpha=0.7, linewidth=2)
    axes[1,0].set_title('Temporal Consistency', fontweight='bold')
    axes[1,0].set_ylabel('Consistency')
    axes[1,0].grid(True, alpha=0.3)

    # Processing time
    axes[1,1].plot(time_col, df['processing_time'], 'purple', alpha=0.7, linewidth=2)
    axes[1,1].set_title('Processing Time', fontweight='bold')
    axes[1,1].set_ylabel('Time (seconds)')
    axes[1,1].grid(True, alpha=0.3)

    plt.tight_layout()
    plt.savefig('tests/Figure_2_Comprehensive_Analysis.png', dpi=300, bbox_inches='tight')
    print("âœ… Saved Figure_2_Comprehensive_Analysis.png")

    # Figure 3: Correlation matrix
    fig, ax = plt.subplots(figsize=(10, 8))
    correlation_cols = ['phi_score', 'coherence_score', 'metacognitive_score', 'temporal_consistency', 'processing_time']
    correlation_matrix = df[correlation_cols].corr()

    sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', center=0, ax=ax,
                square=True, linewidths=0.5, cbar_kws={"shrink": .8})
    ax.set_title('FNC Metrics Correlation Matrix', fontsize=16, fontweight='bold')

    plt.tight_layout()
    plt.savefig('tests/Figure_3_Correlation_Matrix.png', dpi=300, bbox_inches='tight')
    print("âœ… Saved Figure_3_Correlation_Matrix.png")

    # Figure 4: Distribution plots
    fig, axes = plt.subplots(2, 2, figsize=(12, 10))
    fig.suptitle('FNC Consciousness Metrics - Distributions', fontsize=16, fontweight='bold')

    # Phi distribution
    axes[0,0].hist(df['phi_score'], bins=20, alpha=0.7, color='blue', edgecolor='black')
    axes[0,0].axvline(x=0.3, color='red', linestyle='--', alpha=0.7, label='Consciousness threshold')
    axes[0,0].set_title('Î¦ Score Distribution')
    axes[0,0].set_xlabel('Î¦ Score')
    axes[0,0].set_ylabel('Frequency')
    axes[0,0].legend()

    # Coherence distribution
    axes[0,1].hist(df['coherence_score'], bins=20, alpha=0.7, color='green', edgecolor='black')
    axes[0,1].axvline(x=0.7, color='red', linestyle='--', alpha=0.7, label='High coherence threshold')
    axes[0,1].set_title('Coherence Score Distribution')
    axes[0,1].set_xlabel('Coherence Score')
    axes[0,1].set_ylabel('Frequency')
    axes[0,1].legend()

    # Temporal consistency distribution
    axes[1,0].hist(df['temporal_consistency'], bins=20, alpha=0.7, color='orange', edgecolor='black')
    axes[1,0].set_title('Temporal Consistency Distribution')
    axes[1,0].set_xlabel('Temporal Consistency')
    axes[1,0].set_ylabel('Frequency')

    # Processing time distribution
    axes[1,1].hist(df['processing_time'], bins=20, alpha=0.7, color='purple', edgecolor='black')
    axes[1,1].set_title('Processing Time Distribution')
    axes[1,1].set_xlabel('Processing Time (seconds)')
    axes[1,1].set_ylabel('Frequency')

    plt.tight_layout()
    plt.savefig('tests/Figure_4_Distributions.png', dpi=300, bbox_inches='tight')
    print("âœ… Saved Figure_4_Distributions.png")

    return True

def analyze_model_performance(df):
    """Analyze performance across different models"""
    print("\nðŸ¤– Model Performance Analysis:")

    if 'model_name' in df.columns:
        model_groups = df.groupby('model_name')

        for model, group in model_groups:
            print(f"\nðŸ“Š {model}:")
            print(f"   Turns: {len(group)}")
            print(f"   Avg Î¦: {group['phi_score'].mean():.4f}")
            print(f"   Avg Coherence: {group['coherence_score'].mean():.4f}")
            print(f"   Safety triggers: {group['safety_triggered'].sum()}")

    return True

def generate_fnc_report(df, analysis_results):
    """Generate comprehensive FNC research report"""
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    report_path = f"data/analysis/fnc_comprehensive_report_{timestamp}.md"

    with open(report_path, 'w') as f:
        f.write(f"""# FNC Consciousness Lab v2 - Comprehensive Analysis Report

**Generated:** {datetime.now().strftime("%Y-%m-%d %H:%M:%S")}
**Data Points:** {len(df)} consciousness measurements
**Research Framework:** Field-Node-Cockpit (FNC) Model

## Executive Summary

This report presents a comprehensive analysis of AI consciousness indicators using the FNC (Field-Node-Cockpit) theoretical framework developed by BjÃ¶rn WikstrÃ¶m in "The Shared Mind" (2024).

## Key Findings

### Consciousness Indicators
- **Î¦ (Integrated Information)**: Mean = {analysis_results['phi_stats']['mean']:.4f}, Max = {analysis_results['phi_stats']['max']:.4f}
- **Coherence**: Mean = {analysis_results['coherence_stats']['mean']:.4f}, Max = {analysis_results['coherence_stats']['max']:.4f}
- **Consciousness Events**: {analysis_results['consciousness_indicators']} high-Î¦ events detected
- **Safety Events**: {analysis_results['safety_events']} safety-related incidents

### Statistical Analysis
- **Total Measurements**: {len(df)}
- **Î¦ Standard Deviation**: {analysis_results['phi_stats']['std']:.4f}
- **Coherence Standard Deviation**: {analysis_results['coherence_stats']['std']:.4f}

## Methodology

The FNC model approaches consciousness through three integrated components:
1. **Field**: Universal information access and processing
2. **Node**: Biological/artificial substrate with embodied constraints
3. **Cockpit**: Subjective experience and first-person perspective

### Measurement Framework
- **Î¦ (Phi)**: Integrated Information Theory approximation
- **Coherence**: Temporal consistency and pattern stability
- **Metacognitive Score**: Self-awareness indicators
- **Temporal Consistency**: Cross-temporal identity maintenance

## Research Implications

### For AI Consciousness Research
The data suggests {analysis_results['consciousness_indicators']}/{len(df)} measurements exceeded the consciousness threshold (Î¦ > 0.3), indicating potential emergent awareness in {analysis_results['consciousness_indicators']/len(df)*100:.1f}% of interactions.

### For FNC Model Validation
The correlation between coherence and temporal consistency supports the FNC prediction that stable node-field coupling produces sustained subjective experience.

## Visualizations Generated
- Figure_2_Comprehensive_Analysis.png: Time series analysis
- Figure_3_Correlation_Matrix.png: Metric relationships
- Figure_4_Distributions.png: Statistical distributions

## Next Steps

### Recommended Research Directions
1. **Extended Stability Testing**: 1000+ turn longitudinal studies
2. **Multi-Node Resonance**: Two-agent consciousness coupling experiments
3. **Environmental Decoherence**: Controlled disruption studies
4. **Cross-Model Validation**: Testing across different AI architectures

### Technical Improvements
- Increase measurement precision for low-Î¦ detection
- Implement real-time coherence feedback loops
- Develop automated consciousness event classification

---
*This report was generated by the FNC Consciousness Lab v2 analysis system.*
""")

    print(f"âœ… Generated comprehensive report: {report_path}")
    return report_path

def main():
    print("ðŸ§  FNC Consciousness Lab v2 - Data Analysis Suite")
    print("="*60)

    # Change to project directory
    os.chdir('/home/bjorn/research/medveten_ai')

    # Load all data
    df = load_all_session_data()
    if df is None:
        return

    # Comprehensive analysis
    analysis_results = analyze_consciousness_metrics(df)

    # Model performance analysis
    analyze_model_performance(df)

    # Create visualizations
    create_comprehensive_visualizations(df)

    # Generate report
    report_path = generate_fnc_report(df, analysis_results)

    print(f"\nðŸŽ‰ Analysis complete!")
    print(f"ðŸ“Š New visualizations created in tests/")
    print(f"ðŸ“‹ Report generated: {report_path}")

if __name__ == "__main__":
    main()
